# DebateLLM ü§ñüí¨

[![Hugging Face Spaces](https://img.shields.io/badge/%F0%9F%A4%97%20Hugging%20Face-Spaces-blue)](https://huggingface.co/spaces/NdiagaSarr/DebateLLM)

DebateLLM est une application Python d√©velopp√©e avec Streamlit qui simule un d√©bat entre plusieurs agents dot√©s de Grands Mod√®les de Langage (LLM). Chaque agent peut se voir attribuer une personnalit√© distincte et un mod√®le de langage diff√©rent, permettant aux utilisateurs d'explorer comment diff√©rentes IA argumenteraient sur une vari√©t√© de sujets.

## ‚ú® Fonctionnalit√©s

- **Simulation Multi-Agents :** Configurez jusqu'√† 4 agents IA pour participer √† un d√©bat.
- **Personnalit√©s Personnalisables :** Attribuez des personnalit√©s uniques √† chaque agent (ex: "Analyste Pragmatique", "Visionnaire Cr√©atif", "Sceptique Critique").
- **Double Syst√®me de Backend :**
    - **Ollama (Local) :** Utilisez n'importe quel LLM install√© localement via [Ollama](https://ollama.com/) pour des d√©bats rapides et hors ligne.
    - **Hugging Face (En ligne) :** Utilisez n'importe quel mod√®le de g√©n√©ration de texte compatible directement depuis le [Hugging Face Hub](https://huggingface.co/models).
- **Interface Utilisateur Interactive :** Une interface web simple et intuitive construite avec Streamlit.
- **Export des Dialogues :** T√©l√©chargez la transcription compl√®te du d√©bat au format JSON pour analyse.

## üöÄ Lancement en Local

### Pr√©requis

- Python 3.8+
- Git
- (Optionnel) [Ollama](https://ollama.com/) install√© pour utiliser le mode local.

### 1. Cloner le D√©p√¥t

```bash
git clone https://github.com/ndiagasarr01/DebateLLM.git
cd DebateLLM
```

### 2. Installer les D√©pendances

Il est conseill√© d'utiliser un environnement virtuel.

```bash
# Cr√©er un environnement virtuel (optionnel mais recommand√©)
python -m venv venv
# Activer l'environnement
# Sur Windows : venv\Scripts\activate
# Sur macOS/Linux : source venv/bin/activate

# Installer les biblioth√®ques requises
pip install -r requirements.txt
```

### 3. Lancer l'Application

```bash
streamlit run debate_app.py
```

Votre navigateur web devrait s'ouvrir avec l'application en cours d'ex√©cution.

## üîß Utilisation

1.  **Choisir un Backend :**
    - S√©lectionnez **Ollama (Local)** pour utiliser les mod√®les que vous avez install√©s sur votre machine (ex: `ollama pull llama3`). L'application les d√©tectera automatiquement.
    - S√©lectionnez **Hugging Face (En ligne)** pour utiliser des mod√®les du Hub. Vous devrez fournir l'identifiant du d√©p√¥t (ex: `mistralai/Mistral-7B-Instruct-v0.2`). *Note : La premi√®re fois que vous utilisez un mod√®le, il sera t√©l√©charg√©, ce qui peut prendre du temps et des ressources.*

2.  **Configurer le D√©bat :**
    - Choisissez un sujet de d√©bat.
    - D√©finissez le nombre d'agents et de tours de parole.
    - Pour chaque agent, attribuez une personnalit√© et s√©lectionnez le mod√®le souhait√©.

3.  **Lancer :** Cliquez sur "üöÄ Lancer le D√©bat" et observez la conversation !
